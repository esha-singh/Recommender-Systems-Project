{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5SMWvOI46K1"
   },
   "source": [
    "### Goal is to learn vector embeddings for users and movies via Neural Network and predict ratings\n",
    "\n",
    "- Esha Singh\n",
    "- Anirudh Agarwal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "O5qaxonv502c",
    "outputId": "f0c8ddd2-074b-45f3-e1b9-c062ab8c13ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1104</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>639</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>853</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3177</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2162</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating       Time\n",
       "0       0     1104       5  978300760\n",
       "1       0      639       3  978302109\n",
       "2       0      853       3  978301968\n",
       "3       0     3177       4  978300275\n",
       "4       0     2162       5  978824291"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data file\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "ratings_df = pd.read_csv('ratings.dat', \n",
    "                         names=['UserID','MovieID','Rating','Time'], \n",
    "                         sep='::', engine='python')\n",
    "\n",
    "# Label encoding for continuous IDs, required for embedding vector\n",
    "ratings_df['UserID'] = LabelEncoder().fit_transform(ratings_df['UserID'])\n",
    "ratings_df['MovieID'] = LabelEncoder().fit_transform(ratings_df['MovieID'])\n",
    "\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rcU5SfYYRhz"
   },
   "source": [
    "**Benchmarking RMSE value against FunkSVD**\n",
    "\n",
    "*Code snippert derived from previous homework*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of fold # 1 for FunkSVD \t 0.9078703112570627\n",
      "RMSE of fold # 2 for FunkSVD \t 0.8852976347723788\n",
      "RMSE of fold # 3 for FunkSVD \t 0.9310011969700549\n",
      "RMSE of fold # 4 for FunkSVD \t 0.9019645033317578\n",
      "RMSE of fold # 5 for FunkSVD \t 0.8920507731303983\n",
      "Mean RMSE of FunkSVD \t 0.9036368838923305\n"
     ]
    }
   ],
   "source": [
    "from lenskit import util\n",
    "from lenskit.batch import predict\n",
    "from lenskit import crossfold as cv\n",
    "from lenskit.algorithms import funksvd\n",
    "from lenskit.metrics.predict import rmse\n",
    "\n",
    "# Get Recommendations/Predictions\n",
    "def eval(aname, algo, train, test): \n",
    "    algoClone = util.clone(algo)\n",
    "    algoClone.fit(train)\n",
    "    #batch.predict returns a frame with columns user, item, and prediction containing the prediction results.\n",
    "    #If pairs contains a rating column, this result will also contain a rating column.\n",
    "    recs = predict(algoClone, test)\n",
    "    recs['Algorithm'] = aname\n",
    "    \n",
    "    recs.fillna(0, inplace=True)\n",
    "    return recs\n",
    "\n",
    "# Calculating RMSE\n",
    "def rmse_cal(data, kFolds, nSamples, algoName, algoObject): \n",
    "    test_data = []\n",
    "    train_data = []\n",
    "    rmseList =[]\n",
    "    count = 1 # to keep track of the ith fold\n",
    "\n",
    "    for train, test in cv.partition_users(data, kFolds, cv.SampleN(nSamples)):\n",
    "        test_data.append(test)\n",
    "        train_data.append(train)\n",
    "        recs = eval(algoName, algoObject, train, test)\n",
    "        rmseList.append( rmse(recs['prediction'], recs['rating']))\n",
    "        print('RMSE of fold #', count, 'for', algoName ,'\\t', rmseList[count-1])\n",
    "        \n",
    "        count = count+1 \n",
    "    return rmseList\n",
    "\n",
    "#got the best results for features = 20\n",
    "algo_FunkSVD = funksvd.FunkSVD(20) \n",
    "\n",
    "kFolds = 5\n",
    "nSamples =1\n",
    "data = ratings_df.rename(columns={'UserID': 'user', 'MovieID': 'item', 'Rating': 'rating'})\n",
    "rmseFunkSVD = rmse_cal(data, kFolds, nSamples, 'FunkSVD', algo_FunkSVD)\n",
    "print('Mean RMSE of FunkSVD \\t', np.mean(rmseFunkSVD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqKJvVxiStai"
   },
   "source": [
    "**Initialization of User and Item latent vectors**\n",
    "\n",
    "Using Embedding in Keras which maps discrete IDs into continuous vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mm2VnwCkS62N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "class GetVec:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        '''\n",
    "        returns Embedding of vectors\n",
    "        '''\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        '''\n",
    "        going with default initiaizer uniform and no regularizer\n",
    "        '''\n",
    "        x = Embedding(self.input_dim, self.output_dim)(x)\n",
    "        # x = Reshape((self.n_factors,))(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0BHqfayHWyse"
   },
   "source": [
    "**Creating a simple Neural Net**\n",
    "\n",
    "Dot product of user and item vectors is optimized over MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vly3VCr6WqOQ"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras import backend as B\n",
    "from keras.layers import Input, Reshape, Dot\n",
    "\n",
    "# custom error function\n",
    "def rmse(y_true, y_pred):\n",
    "    return B.sqrt(B.mean(B.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def basicNN(n_users, n_movies, dim_latent=20):\n",
    "    '''\n",
    "    Creates a graph for keras model\n",
    "    '''\n",
    "    # Creating partially known shaped tensors \n",
    "    I1 = Input(shape=(1,))\n",
    "    I2 = Input(shape=(1,))\n",
    "\n",
    "    # Getting vectors\n",
    "    # default latent feature size=20, this is based on tuning in previous homework\n",
    "    E1 = GetVec(n_users, dim_latent)(I1)\n",
    "    E2 = GetVec(n_movies, dim_latent)(I2)\n",
    "\n",
    "    # Reshaping embeddings as latent feature vectors\n",
    "    V1 = Reshape((dim_latent,))(E1)\n",
    "    V2 = Reshape((dim_latent,))(E2)\n",
    "\n",
    "    # Performing dot product\n",
    "    Y = Dot(axes=1)([V1, V2])\n",
    "\n",
    "    # Model creation and compiling\n",
    "    model = Model(inputs=[I1, I2], outputs=Y)\n",
    "    sgd = optimizers.SGD(lr=0.5)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd, metrics=[rmse])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rCRmg6jgjC4"
   },
   "source": [
    "**BasicNN Training and evaluation**\n",
    "\n",
    "Not running k-fold cross validation as running NN is expensive and time consuming.<br />\n",
    "Evaluation done by splitting data into train, validation and test sets.<br />\n",
    "Default configuration for optimiser works best.<br />\n",
    "No of epochs decided on the basis of observation, when rmse stops changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGMD-9fNgQ0R"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshasingh/env/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810169 samples, validate on 90019 samples\n",
      "Epoch 1/10\n",
      "810169/810169 [==============================] - 26s 32us/step - loss: 3.0630 - rmse: 1.2576 - val_loss: 0.9472 - val_rmse: 0.7668\n",
      "Epoch 2/10\n",
      "810169/810169 [==============================] - 25s 31us/step - loss: 0.8842 - rmse: 0.7417 - val_loss: 0.8667 - val_rmse: 0.7343\n",
      "Epoch 3/10\n",
      "810169/810169 [==============================] - 25s 31us/step - loss: 0.7991 - rmse: 0.7040 - val_loss: 0.8297 - val_rmse: 0.7158\n",
      "Epoch 4/10\n",
      "810169/810169 [==============================] - 25s 31us/step - loss: 0.7378 - rmse: 0.6758 - val_loss: 0.8213 - val_rmse: 0.7111\n",
      "Epoch 5/10\n",
      "810169/810169 [==============================] - 24s 30us/step - loss: 0.6985 - rmse: 0.6573 - val_loss: 0.8293 - val_rmse: 0.7144\n",
      "Epoch 6/10\n",
      "810169/810169 [==============================] - 24s 30us/step - loss: 0.6734 - rmse: 0.6452 - val_loss: 0.8310 - val_rmse: 0.7151\n",
      "Epoch 7/10\n",
      "810169/810169 [==============================] - 24s 30us/step - loss: 0.6556 - rmse: 0.6368 - val_loss: 0.8416 - val_rmse: 0.7178\n",
      "Epoch 8/10\n",
      "810169/810169 [==============================] - 24s 30us/step - loss: 0.6431 - rmse: 0.6303 - val_loss: 0.8385 - val_rmse: 0.7162\n",
      "Epoch 9/10\n",
      "810169/810169 [==============================] - 24s 30us/step - loss: 0.6335 - rmse: 0.6255 - val_loss: 0.8471 - val_rmse: 0.7190\n",
      "Epoch 10/10\n",
      "810169/810169 [==============================] - 24s 30us/step - loss: 0.6255 - rmse: 0.6214 - val_loss: 0.8523 - val_rmse: 0.7211\n",
      "100021/100021 [==============================] - 1s 9us/step\n",
      "RMSE Error:  0.7218112349510193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def dataTrainEval(DNfun, epochs=10):\n",
    "    # data preprocessing\n",
    "    n_users = ratings_df['UserID'].nunique()\n",
    "    n_movies = ratings_df['MovieID'].nunique()\n",
    "\n",
    "    # Splitting data into parts\n",
    "    data = ratings_df[['UserID', 'MovieID']].values\n",
    "    target = ratings_df['Rating'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1)\n",
    "\n",
    "    # Flattening columns\n",
    "    X_train = [X_train[:, 0], X_train[:, 1]]\n",
    "    X_test = [X_test[:, 0], X_test[:, 1]]\n",
    "\n",
    "    # Initializing model\n",
    "    model = DNfun(n_users, n_movies)\n",
    "\n",
    "    # Fitting \n",
    "    model.fit(x=X_train, y=y_train, epochs=epochs, verbose=1, validation_split=0.1)\n",
    "\n",
    "    # Evaluation\n",
    "    error = model.evaluate(x=X_test, y=y_test)\n",
    "    return error\n",
    "\n",
    "# Running function\n",
    "print ('RMSE Error: ', dataTrainEval(basicNN, epochs=10)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkwnoIcGbEq-"
   },
   "source": [
    "**Extra Credit**\n",
    "\n",
    "Approach 1: Trying different optimiser configurations (This optimizer and learning rate works best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "ZnE89gdi2FvK",
    "outputId": "7b815fdf-58e6-4d19-b517-2144bcf8aebf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshasingh/env/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810169 samples, validate on 90019 samples\n",
      "Epoch 1/5\n",
      "810169/810169 [==============================] - 59s 72us/step - loss: 2.5453 - rmse: 1.1455 - val_loss: 0.9105 - val_rmse: 0.7525\n",
      "Epoch 2/5\n",
      "810169/810169 [==============================] - 1080s 1ms/step - loss: 0.8624 - rmse: 0.7311 - val_loss: 0.8516 - val_rmse: 0.7264\n",
      "Epoch 3/5\n",
      "810169/810169 [==============================] - 63s 78us/step - loss: 0.7710 - rmse: 0.6889 - val_loss: 0.8221 - val_rmse: 0.7127\n",
      "Epoch 4/5\n",
      "810169/810169 [==============================] - 64s 79us/step - loss: 0.6844 - rmse: 0.6468 - val_loss: 0.8194 - val_rmse: 0.7105\n",
      "Epoch 5/5\n",
      "810169/810169 [==============================] - 63s 77us/step - loss: 0.6096 - rmse: 0.6082 - val_loss: 0.8379 - val_rmse: 0.7173\n",
      "100021/100021 [==============================] - 1s 10us/step\n",
      "RMSE Error:  0.7200255393981934\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "def confNN(n_users, n_movies, dim_latent=50):\n",
    "    '''\n",
    "    Creates a graph for keras model\n",
    "    '''\n",
    "    # Creating partially known shaped tensors \n",
    "    I1 = Input(shape=(1,))\n",
    "    I2 = Input(shape=(1,))\n",
    "\n",
    "    # Getting vectors\n",
    "    # default latent feature size=20, this is based on tuning in previous homework\n",
    "    E1 = GetVec(n_users, dim_latent)(I1)\n",
    "    E2 = GetVec(n_movies, dim_latent)(I2)\n",
    "\n",
    "    # Reshaping embeddings as latent feature vectors\n",
    "    V1 = Reshape((dim_latent,))(E1)\n",
    "    V2 = Reshape((dim_latent,))(E2)\n",
    "\n",
    "    # Performing dot product\n",
    "    Y = Dot(axes=1)([V1, V2])\n",
    "\n",
    "    # Model creation and compiling\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    model = Model(inputs=[I1, I2], outputs=Y)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Running function\n",
    "print ('RMSE Error: ', dataTrainEval(confNN, epochs=5)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ahaApDnRXauj"
   },
   "source": [
    "**Extra Credit**\n",
    "\n",
    "Approach 2: Adding more Dense layers, making NN deeper <br />\n",
    "Also, in the final layer we can introduce non-linearity in the form of 'Sigmoid'. <br />\n",
    "Then scale the output in the 1-5 ratings scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "biOaWAwrXoUv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshasingh/env/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810169 samples, validate on 90019 samples\n",
      "Epoch 1/5\n",
      "810169/810169 [==============================] - 39s 48us/step - loss: 0.9787 - rmse: 0.7770 - val_loss: 0.9081 - val_rmse: 0.7471\n",
      "Epoch 2/5\n",
      "810169/810169 [==============================] - 37s 45us/step - loss: 0.8998 - rmse: 0.7431 - val_loss: 0.8893 - val_rmse: 0.7377\n",
      "Epoch 3/5\n",
      "810169/810169 [==============================] - 37s 46us/step - loss: 0.8810 - rmse: 0.7318 - val_loss: 0.8800 - val_rmse: 0.7321\n",
      "Epoch 4/5\n",
      "810169/810169 [==============================] - 38s 46us/step - loss: 0.8662 - rmse: 0.7231 - val_loss: 0.8665 - val_rmse: 0.7248\n",
      "Epoch 5/5\n",
      "810169/810169 [==============================] - 38s 47us/step - loss: 0.8505 - rmse: 0.7137 - val_loss: 0.8614 - val_rmse: 0.7194\n",
      "100021/100021 [==============================] - 1s 10us/step\n",
      "RMSE Error:  0.7195802927017212\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Add, Activation, Lambda, Dense\n",
    "\n",
    "def deepNN(n_users, n_movies, dim_latent=20):\n",
    "    '''\n",
    "    Creates a graph for keras model\n",
    "    '''\n",
    "    # Creating partially known shaped tensors \n",
    "    I1 = Input(shape=(1,))\n",
    "    I2 = Input(shape=(1,))\n",
    "\n",
    "    # Getting vectors\n",
    "    # default latent feature size=20this is based on tuning in previous homework\n",
    "    E1 = GetVec(n_users, dim_latent)(I1)\n",
    "    E2 = GetVec(n_movies, dim_latent)(I2)\n",
    "\n",
    "    # Creating more layers (introducing more non-linearity)\n",
    "    E1 = Dense(dim_latent, activation='sigmoid')(E1)\n",
    "    E2 = Dense(dim_latent, activation='sigmoid')(E2)\n",
    "\n",
    "    # Reshaping embeddings as latent feature vectors\n",
    "    V1 = Reshape((dim_latent,))(E1)\n",
    "    V2 = Reshape((dim_latent,))(E2)\n",
    "\n",
    "    # Performing dot product\n",
    "    Y = Dot(axes=1)([V1, V2])\n",
    "\n",
    "    # Non-linearity and scaling (As we already know the scales)\n",
    "    min_rat = 1 \n",
    "    max_rat = 5\n",
    "    Y = Activation('sigmoid')(Y)\n",
    "    Y = Lambda(lambda x: x * (max_rat - min_rat) + min_rat)(Y)\n",
    "\n",
    "    # Model creation and compiling\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    model = Model(inputs=[I1, I2], outputs=Y)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Running function\n",
    "print ('RMSE Error: ', dataTrainEval(deepNN, epochs=5)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a21B1lM5u1X3"
   },
   "source": [
    "**Extra Credit**\n",
    "\n",
    "Approach 3: The performance of this Neural Net can be kicked up by adding user and item biases. <br />\n",
    "These biases can internally help normalize ratings and are required as intercepts to balance weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "krmDW3d81dcr",
    "outputId": "b34a3e4c-95d1-4540-8fd9-ee62da20fa14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshasingh/env/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810169 samples, validate on 90019 samples\n",
      "Epoch 1/5\n",
      "810169/810169 [==============================] - 35s 43us/step - loss: 0.9391 - rmse: 0.7728 - val_loss: 0.7905 - val_rmse: 0.7014\n",
      "Epoch 2/5\n",
      "810169/810169 [==============================] - 35s 44us/step - loss: 0.7434 - rmse: 0.6768 - val_loss: 0.7518 - val_rmse: 0.6800\n",
      "Epoch 3/5\n",
      "810169/810169 [==============================] - 36s 44us/step - loss: 0.6774 - rmse: 0.6430 - val_loss: 0.7465 - val_rmse: 0.6761\n",
      "Epoch 4/5\n",
      "810169/810169 [==============================] - 36s 44us/step - loss: 0.6306 - rmse: 0.6178 - val_loss: 0.7591 - val_rmse: 0.6804\n",
      "Epoch 5/5\n",
      "810169/810169 [==============================] - 36s 44us/step - loss: 0.6012 - rmse: 0.6012 - val_loss: 0.7747 - val_rmse: 0.6861\n",
      "100021/100021 [==============================] - 1s 10us/step\n",
      "RMSE Error:  0.6838966012001038\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Add, Activation, Lambda\n",
    "\n",
    "def biasNN(n_users, n_movies, dim_latent=20):\n",
    "    '''\n",
    "    Creates a graph for keras model\n",
    "    '''\n",
    "    # Creating partially known shaped tensors \n",
    "    I1 = Input(shape=(1,))\n",
    "    I2 = Input(shape=(1,))\n",
    "\n",
    "    # Getting vectors\n",
    "    # default latent feature size=20this is based on tuning in previous homework\n",
    "    E1 = GetVec(n_users, dim_latent)(I1)\n",
    "    E2 = GetVec(n_movies, dim_latent)(I2)\n",
    "\n",
    "    # One bias for each uesr and each movie\n",
    "    E1_bias = GetVec(n_users, 1)(I1)\n",
    "    E2_bias = GetVec(n_movies, 1)(I2)\n",
    "\n",
    "    # Reshaping embeddings as latent feature vectors\n",
    "    V1 = Reshape((dim_latent,))(E1)\n",
    "    V2 = Reshape((dim_latent,))(E2)\n",
    "\n",
    "    # Performing dot product\n",
    "    Y = Dot(axes=1)([V1, V2])\n",
    "\n",
    "    # Reshaping and adding biases\n",
    "    E1_bias = Reshape((1,))(E1_bias)\n",
    "    E2_bias = Reshape((1,))(E1_bias)\n",
    "    Y = Add()([Y, E1_bias, E2_bias])\n",
    "\n",
    "    # Non-linearity and scaling (As we already know the scales)\n",
    "    min_rat = 1 \n",
    "    max_rat = 5\n",
    "    Y = Activation('sigmoid')(Y)\n",
    "    Y = Lambda(lambda x: x * (max_rat - min_rat) + min_rat)(Y)\n",
    "\n",
    "    # Model creation and compiling\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    model = Model(inputs=[I1, I2], outputs=Y)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Running function\n",
    "print ('RMSE Error: ', dataTrainEval(biasNN, epochs=5)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra Credit**\n",
    "\n",
    "Approach 4: Switching activation functions and learning rates in our deep NN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshasingh/env/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810169 samples, validate on 90019 samples\n",
      "Epoch 1/5\n",
      "810169/810169 [==============================] - 38s 47us/step - loss: 0.8715 - rmse: 0.7361 - val_loss: 0.8055 - val_rmse: 0.7157\n",
      "Epoch 2/5\n",
      "810169/810169 [==============================] - 38s 47us/step - loss: 0.7624 - rmse: 0.6874 - val_loss: 0.7762 - val_rmse: 0.6992\n",
      "Epoch 3/5\n",
      "810169/810169 [==============================] - 38s 47us/step - loss: 0.7158 - rmse: 0.6634 - val_loss: 0.7656 - val_rmse: 0.6912\n",
      "Epoch 4/5\n",
      "810169/810169 [==============================] - 38s 47us/step - loss: 0.6859 - rmse: 0.6475 - val_loss: 0.7821 - val_rmse: 0.7037\n",
      "Epoch 5/5\n",
      "810169/810169 [==============================] - 38s 47us/step - loss: 0.6658 - rmse: 0.6370 - val_loss: 0.7652 - val_rmse: 0.6862\n",
      "100021/100021 [==============================] - 1s 10us/step\n",
      "RMSE Error:  0.6887091994285583\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Add, Activation, Lambda, Dense\n",
    "\n",
    "def deepNN2(n_users, n_movies, dim_latent=20):\n",
    "    '''\n",
    "    Creates a graph for keras model\n",
    "    '''\n",
    "    # Creating partially known shaped tensors \n",
    "    I1 = Input(shape=(1,))\n",
    "    I2 = Input(shape=(1,))\n",
    "\n",
    "    # Getting vectors\n",
    "    # default latent feature size=20this is based on tuning in previous homework\n",
    "    E1 = GetVec(n_users, dim_latent)(I1)\n",
    "    E2 = GetVec(n_movies, dim_latent)(I2)\n",
    "\n",
    "    # Creating more layers (introducing more non-linearity)\n",
    "    E1 = Dense(dim_latent, activation='relu')(E1)\n",
    "    E2 = Dense(dim_latent, activation='relu')(E2)\n",
    "\n",
    "    # Reshaping embeddings as latent feature vectors\n",
    "    V1 = Reshape((dim_latent,))(E1)\n",
    "    V2 = Reshape((dim_latent,))(E2)\n",
    "\n",
    "    # Performing dot product\n",
    "    Y = Dot(axes=1)([V1, V2])\n",
    "\n",
    "    # Non-linearity and scaling (As we already know the scales)\n",
    "    min_rat = 1 \n",
    "    max_rat = 5\n",
    "    Y = Activation('relu')(Y)\n",
    "    Y = Lambda(lambda x: x * (max_rat - min_rat) + min_rat)(Y)\n",
    "\n",
    "    # Model creation and compiling\n",
    "    opt = optimizers.Adam(lr=0.001)\n",
    "    model = Model(inputs=[I1, I2], outputs=Y)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=[rmse])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Running function\n",
    "print ('RMSE Error: ', dataTrainEval(deepNN2, epochs=5)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "- RMSE for FunkSVD: **0.904**\n",
    "- RMSE for best config DeepNN: **0.684**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further scope of improvement:\n",
    "\n",
    "- Trying different activation functions in the outer layer\n",
    "- Different initializers for the embedding\n",
    "- Different learning rates, with clampers and momentum in optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ofGt368KBKh5"
   },
   "source": [
    "#### References\n",
    "- https://keras.io/\n",
    "- https://www.youtube.com/watch?v=UOEhojCzWrY&list=PLgJhDSE2ZLxaPX0jteHZG4skdj8ZrST9d\n",
    "- https://towardsdatascience.com/building-a-book-recommendation-system-using-keras-1fba34180699, \n",
    "- https://medium.com/@jdwittenauer/deep-learning-with-keras-recommender-systems-e7b99cb29929"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "reco_hw4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
